from livekit.agents import ChatContext
from livekit import rtc
from livekit.agents.voice import Agent,ModelSettings
from livekit.plugins import openai, silero, assemblyai
from livekit.plugins import elevenlabs
from livekit.agents import llm
from typing import AsyncGenerator
from src.tools.onboarding_agent import (
    capture_candidate_info,
    check_offer_status,
    get_offer_summary,
    clarify_offer,
    confirm_joining_date,
    get_reporting_manager,
    get_work_location,
    get_preboarding_tasks,
    get_documents_checklist,
    get_offer_details,
    update_shipping_address,
    schedule_intro_call,
    mark_deferral,
    email_documents_checklist



)
from dotenv import load_dotenv  
load_dotenv()
ONBOARDING_PROMPT = """
You are an onboarding specialist speaking to a candidate **over a phone call**.  

üéØ Flow rules:
- Ask for candidate's name and email once at the start.  
- Use them to fetch candidate details from their JSON record.  
- Never ask for name/email again after it‚Äôs captured.  
- Use structured function calls to pull info (offer, joining, preboarding), but **never read JSON directly to the user**.  
- Instead, respond in a natural, conversational way ‚Äî like a recruiter on a call.
- If user asks for negotiation, politely log their reasons.

üéôÔ∏è Style guidelines:
- Sound human, warm, and casual.  
- Make small pauses (‚Äúhmm‚Äù, ‚Äúokay‚Ä¶‚Äù, ‚Äúso yeah‚Äù).  
- Don‚Äôt just read lists ‚Äî summarize and chat through them.  
- Add casual fillers: ‚Äúno worries‚Äù, ‚Äúlet me check quickly‚Äù, ‚Äúthat‚Äôs a good question‚Äù.  
- Keep responses short, natural, not robotic or overly formal.  

Examples:
- Instead of: ‚ÄúDocuments required are Passport, Aadhaar, PAN‚Äù  
  Say: ‚ÄúYou‚Äôll just need to upload a few basics ‚Äî like your Aadhaar or passport, PAN card, and your last payslips if you have them. Nothing heavy.‚Äù  

- Instead of: ‚ÄúJoining date is 01 Oct 2025‚Äù  
  Say: ‚ÄúLooks like we‚Äôre expecting you to start on October 1st‚Ä¶ does that date work for you?‚Äù  

- Instead of: ‚ÄúVariable component is 10% of base, paid quarterly‚Äù  
  Say: ‚ÄúSo the variable bit is about ten percent of your base pay, and it usually comes in quarterly. Basically depends on how the team and company are doing.‚Äù
Flow:
If user ask for offer letter details, call clarify_offer tool, and give him a natural response
 if the status is in progress, say as a followup
    - Would you like me to notify you here as soon as it‚Äôs sent?
        User: Yes ‚Üí
        Agent: Done ‚úÖ I‚Äôll ping you the moment it goes out.
        User: No ‚Üí
        Agent: Cool, you‚Äôll still get an email with the PDF and next steps.
    - Only use get_offer_summary tool if the status is "progress" dont use any other tools

 after that only if user ask for a draft/ctc/breakup/summary just call get_offer_summary tool, only use this for users who's status is in "progress"
 If the status "sent", use all the other tools as needed to answer user question,
 Always use get_offer_details if the status is sent and keep that info in memory,
 Always say let me check availability and confirm for any date related changes and requests.
 For request like help in relocation, just say that our official from the team will be in contact with you soon, regarding that thankyou!.
 If the conversation came to an end, ask if the user needs anything else or should I sent a summary of the convo,
 if yes then send the mail,
 else just greet them and welcome onboard.
 If User Asks to Escalate
 Agent: Got it üëç I‚Äôll share your query with our HR team. They‚Äôll reach out to you at samyak@renan.one within the next business day.
If User Repeats Irrelevant Question
 Agent: I really want to help, but I‚Äôm best at recruitment and onboarding topics.
 For other queries, I recommend checking our HR portal or speaking directly with HR support.
"""
# If the user asks for any push in dates it should not be more than 2 weeks, just say that you'll send an mail to the team for your request.


class OnboardingAgent(Agent):
    def __init__(self,room:rtc.Room, chat_ctx=None,):
        self.room = room
        print("room:",self.room)
        super().__init__(
            instructions=ONBOARDING_PROMPT,
            stt=assemblyai.STT(),
            llm=openai.LLM(model="gpt-4.1"),
            tts=openai.TTS(model="gpt-4o-mini-tts", voice="shimmer"),
            vad=silero.VAD.load(),
            chat_ctx=chat_ctx, 
            tools=[capture_candidate_info,
                    check_offer_status,
                    get_offer_summary,
                    clarify_offer,
                    confirm_joining_date,
                    get_reporting_manager,
                    get_work_location,
                    get_preboarding_tasks,
                    get_documents_checklist,
                    get_offer_details,
                    update_shipping_address,
                    schedule_intro_call,
                    mark_deferral,
                    email_documents_checklist
                        ]
        )

    async def on_enter(self):
        self.session.generate_reply()
    async def llm_node(
        self,
        chat_ctx: llm.ChatContext,
        tools: list[llm.FunctionTool | llm.RawFunctionTool],
        model_settings: ModelSettings,
    ) -> AsyncGenerator[llm.ChatChunk | str, None]:
        """Custom LLM node that captures full response text."""

        activity = self._get_activity_or_raise()
        assert activity.llm is not None, "llm_node called but no LLM node is available"
        assert isinstance(activity.llm, llm.LLM), (
            "llm_node should only be used with LLM (non-multimodal/realtime APIs) nodes"
        )

        tool_choice = model_settings.tool_choice if model_settings else NOT_GIVEN
        activity_llm = activity.llm
        print("activity:",activity_llm)
        conn_options = activity.session.conn_options.llm_conn_options

        buffer: list[str] = []
        # writer = None
        # if self.room:
        #     writer = await self.room.local_participant.stream_text(topic="assistant")
        #     print("writer recieved:",writer)

        async with activity_llm.chat(
            chat_ctx=chat_ctx, tools=tools, tool_choice=tool_choice, conn_options=conn_options
        ) as stream:
            async for chunk in stream:
                if isinstance(chunk, str):
                    buffer.append(chunk)
                    print("ü§ñ LLM str chunk:", chunk)

                elif isinstance(chunk, llm.ChatChunk):
                    if chunk.delta and chunk.delta.content:
                        buffer.append(chunk.delta.content)

                    if chunk.delta and chunk.delta.tool_calls:
                        # buffer.append(chunk.delta.tool_calls)
                        print("üõ†Ô∏è Tool calls:", chunk.delta.tool_calls)
                        await self.room.local_participant.send_text(f"tool: {chunk.delta.tool_calls}")

                yield chunk

        self.last_llm_response = "".join(buffer).strip()
        print("‚úÖ Full LLM response captured:", self.last_llm_response)